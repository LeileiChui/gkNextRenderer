#version 460
#extension GL_ARB_gpu_shader_int64 : require
#extension GL_ARB_shader_clock : require
#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_ray_tracing : require

#include "Heatmap.glsl"
#include "Random.glsl"
#include "RayPayload.glsl"
#include "Material.glsl"
#include "UniformBufferObject.glsl"

layout(binding = 0, set = 0) uniform accelerationStructureEXT Scene;
layout(binding = 3) readonly uniform UniformBufferObjectStruct { UniformBufferObject Camera; };
layout(binding = 6) readonly buffer MaterialArray { Material[] Materials; };

layout(binding = 10, rgba32f) uniform image2D AccumulationImage;
layout(binding = 11, rg16f) uniform image2D MotionVectorImage;
layout(binding = 12, r32ui) uniform uimage2D VisibilityBuffer;
layout(binding = 13, r32ui) uniform uimage2D Visibility1Buffer;
layout(binding = 14, rgba16f) uniform image2D OutAlbedoBuffer;
layout(binding = 15, rgba16f) uniform image2D OutNormalBuffer;
layout(binding = 16, r8ui) uniform uimage2D AdaptiveSampleBuffer;

layout(location = 0) rayPayloadEXT RayPayload Ray;

bool NextRayColor(inout vec3 origin, inout vec3 scatterDir, inout vec3 outRayColor)
{ 
	traceRayEXT(Scene, gl_RayFlagsOpaqueEXT, 0xff, 0, 0, 0,origin.xyz, EPS, scatterDir, INF, 0);
	if(Ray.BounceCount == Camera.NumberOfBounces)
	{
		outRayColor *= vec3(0);
		return true;
	} 
	
// RR should apply by workgroup, for performance
	
//	else if(Ray.BounceCount > Camera.RR_MIN_DEPTH)
//	{
//		const Material material = Materials[Ray.MaterialIndex];
//		float rr_scale =  material.MaterialModel == MaterialDielectric ? (Ray.FrontFace ? 1.0 / material.RefractionIndex : material.RefractionIndex) : 1.0;
//		float rr_prob = min(0.95f, luminance(atten) * rr_scale);
//		if (rr_prob < RandomFloat(Ray.RandomSeed))
//		{
//			return emit + atten * Ray.pdf;
//		}
//		atten *= min( 1.f / rr_prob, 20.f );
//	}
	
	origin = origin + scatterDir * Ray.Distance;
	scatterDir = Ray.ScatterDirection;
	
	if(Ray.Exit)
	{
		outRayColor *= Ray.EmitColor.rgb;
		return true;
	}
	outRayColor *= Ray.Attenuation * Ray.pdf;
	return false;
}
		
bool PrimaryRayColor(inout vec3 origin, inout vec3 scatterDir, inout vec3 outRayColor, out vec4 gbuffer, out vec4 albedo, out vec4 motionVector, out uint primitiveId)
{
	// Start
	Ray.BounceCount = 0;
	// trace ray
	traceRayEXT(Scene, gl_RayFlagsOpaqueEXT, 0xff, 0, 0, 0,
	origin.xyz, EPS, scatterDir, INF, 0);
	
	// here may miss
	origin = origin + scatterDir * Ray.Distance;
	scatterDir = Ray.ScatterDirection;
	
	// fetch albedo
	gbuffer = vec4(Ray.GBuffer.xyz, Ray.Distance);
	albedo = vec4(Ray.Albedo.rgb, Ray.GBuffer.w);
	
	vec2 size = imageSize(MotionVectorImage);
	vec4 currFrameHPos = Camera.ViewProjection * vec4(origin, 1);
	vec2 currfpos = vec2((currFrameHPos.xy / currFrameHPos.w * 0.5 + 0.5) * vec2(size));
	vec4 prevFrameHPos = Camera.PrevViewProjection * vec4(origin, 1);
	vec2 prevfpos = vec2((prevFrameHPos.xy / prevFrameHPos.w * 0.5 + 0.5) * vec2(size));
	motionVector = Ray.Distance < -5 ? vec4(0) : vec4(prevfpos - currfpos,0,0);
	primitiveId = Ray.primitiveId;
	
	if(Ray.Exit)
	{
		outRayColor *= Ray.EmitColor.rgb;
		return true;
	}
	outRayColor *= Ray.Attenuation * Ray.pdf;
	return false;
}

void main() 
{
	bool isEvenFrame = Camera.TotalFrames % 2 == 0;
	// use checkerbord to skip sample
	int adder = Camera.TotalFrames % 2 == 0 ? 1 : 0;
	
	ivec2 ipos = ivec2(gl_LaunchIDEXT.xy);
	vec2 isize = vec2(gl_LaunchSizeEXT.xy);

	if(Camera.UseCheckerBoard)
	{
		ipos = ipos * ivec2(2,1);
		isize = isize * vec2(2,1);
		if((gl_LaunchIDEXT.y + adder) % 2 == 0) 
		{
			ipos.x += 1;
		}
	}
    
	const uint64_t clock = Camera.ShowHeatmap ? clockARB() : 0;

	// Initialise separate random seeds for the pixel and the rays.
	// - pixel: we want the same random seed for each pixel to get a homogeneous anti-aliasing.
	// - ray: we want a noisy random seed, different for each pixel.
	Ray.RandomSeed = InitRandomSeed(gl_LaunchIDEXT.x, gl_LaunchIDEXT.y, Camera.TotalFrames);
	Ray.RandomSeed.w = Camera.RandomSeed;
	//uvec4 pixelRandomSeed = Ray.RandomSeed; pixelRandomSeed.w = Camera.RandomSeed + 1;
    //vec2 uvOffset = RandomFloat2(pixelRandomSeed) / isize;
    const vec3 exitColor = vec3(0.0);
	vec3 pixelColor = vec3(0);
			
	vec4 gbuffer = vec4(0);
	vec4 albedo = vec4(0);
	vec4 motionvector = vec4(0);
	
	// Accumulate all the rays for this pixels.
			
	// Adaptive Sampling
	// this can be judge by current frame, first sample we can determin if we dismiss the cache, and catch up samples
	uint sampleTimes = Camera.NumberOfSamples;
		
	// dynamic sampleTimes;
	uint multisamplecount = 1;
	if( Camera.TotalFrames > 0 )
	{
		multisamplecount = imageLoad(AdaptiveSampleBuffer, ipos).r;
	}
	bool multisample = multisamplecount > 1;
	if(multisample)
	{
		sampleTimes = clamp(Camera.NumberOfSamples * 4, 1, Camera.MaxAdaptiveSample);
	}
		
	ivec2 imgSize = imageSize(Visibility1Buffer);
			
	
	for (uint s = 0; s < sampleTimes; ++s)
	{
		const vec2 pixel = vec2(ipos);
		vec2 uv = (pixel / isize) * 2.0 - 1.0;
		// anti aliasing
        //uv += uvOffset;
       
		vec2 offset = vec2(0);//Camera.Aperture / 2 * RandomInUnitDisk(Ray.RandomSeed);
		vec4 origin = Camera.ModelViewInverse * vec4(offset, 0, 1);
		vec4 target = Camera.ProjectionInverse * (vec4(uv.x, uv.y, 1, 1));
		vec4 direction = Camera.ModelViewInverse * vec4(normalize(target.xyz), 0);
		
		vec4 s_albedo = vec4(0);
		uint primitiveId = 0;
		vec3 rayColor = vec3(1);
		
		if( !PrimaryRayColor(origin.xyz, direction.xyz, rayColor, gbuffer, s_albedo, motionvector, primitiveId) )
        {
            for(uint b = 0; b < 10; ++b)
            {	
                if( NextRayColor(origin.xyz, direction.xyz, rayColor) )
                {
                    break;
                }
            }
        }

		pixelColor += rayColor;
		
		if( s == 0 )
		{
			//imageStore(GBufferImage, ipos, gbuffer);
			imageStore(MotionVectorImage, ipos, motionvector);
			if(isEvenFrame)
			{
				imageStore(VisibilityBuffer, ipos, ivec4(primitiveId,0, 0, 0));
			}
			else
			{
				imageStore(Visibility1Buffer, ipos, ivec4(primitiveId,0, 0, 0));
			}
			imageStore(OutAlbedoBuffer, ipos, s_albedo);
			imageStore(OutNormalBuffer, ipos, gbuffer);

		    // after the first spp, we could judge if reproject miss with previous primitive buffer
		
			vec2 prevfpos = vec2(ipos) + motionvector.rg;
			ivec2 previpos = ivec2( floor(ipos + motionvector.rg) );

			if( length(motionvector.xy) > 0.01 )
			{
				uint prev_primitive_index0 = isEvenFrame ? imageLoad(Visibility1Buffer, previpos + ivec2(0, 0)).r : imageLoad(VisibilityBuffer, previpos + ivec2(0, 0)).r;
				uint prev_primitive_index1 = isEvenFrame ? imageLoad(Visibility1Buffer, previpos + ivec2(0, 1)).r : imageLoad(VisibilityBuffer, previpos + ivec2(0, 1)).r;
				uint prev_primitive_index2 = isEvenFrame ? imageLoad(Visibility1Buffer, previpos + ivec2(1, 0)).r : imageLoad(VisibilityBuffer, previpos + ivec2(1, 0)).r;
				uint prev_primitive_index3 = isEvenFrame ? imageLoad(Visibility1Buffer, previpos + ivec2(1, 1)).r : imageLoad(VisibilityBuffer, previpos + ivec2(1, 1)).r;
		
				bool miss = any(notEqual(uvec4(prev_primitive_index0, prev_primitive_index1, prev_primitive_index2, prev_primitive_index3), uvec4(primitiveId)));

				if (miss)
				{
					sampleTimes = Camera.NumberOfSamples * 4;
					multisamplecount = Camera.TemporalFrames / 4;
				}
			}
		}
	}
		
	// record adaptivesamplebuffer
	multisamplecount = max(1, multisamplecount - 1);
	imageStore(AdaptiveSampleBuffer, ipos, uvec4(multisamplecount));
    
    pixelColor = pixelColor / sampleTimes;
	
	if (Camera.ShowHeatmap)
	{
		const uint64_t deltaTime = clockARB() - clock;
		const float heatmapScale = 1000000.0f * Camera.HeatmapScale * Camera.HeatmapScale;
		const float deltaTimeScaled = clamp(float(deltaTime) / heatmapScale, 0.0f, 1.0f);
		pixelColor = heatmap(deltaTimeScaled) * 50.0;
	}

	// output to accumulation directly
	imageStore(AccumulationImage, ipos, vec4(pixelColor, float(sampleTimes)));
}
